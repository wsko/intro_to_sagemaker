{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Hello\\! As an AWS Solutions Architect, I’ve designed this workflow to be streamlined and cost-effective, leveraging the serverless nature of **Amazon Athena** and **SageMaker AI**.\n",
        "\n",
        "Since you are running this as an admin, you already have the necessary IAM permissions to create buckets and run crawlers. Here is your step-by-step implementation guide.\n",
        "\n",
        "-----\n",
        "\n",
        "## Phase 1: Data Lake Setup (S3 & Glue)\n",
        "\n",
        "### 1\\. Create the S3 Bucket\n",
        "\n",
        "  * Navigate to the **S3 Console**.\n",
        "  * Click **Create bucket**.\n",
        "  * **Bucket name:** `olist-analytics-data-[your-account-id]` (must be globally unique).\n",
        "  * Keep default settings (Block all public access should be **on**).\n",
        "\n",
        "### 2\\. Upload OLIST CSV Files\n",
        "\n",
        "  * Organize your local OLIST files into folders if possible (e.g., `orders/`, `products/`, `customers/`).\n",
        "  * In the S3 console, enter your bucket and click **Upload**.\n",
        "  * Drag and drop the CSV files.\n",
        "    > **Architect's Tip:** Ensure your folder structure is clean, as the Glue Crawler will use the folder names to define the table names in Athena.\n",
        "\n",
        "### 3\\. Create Athena Database via Glue Crawler\n",
        "\n",
        "We will use a Crawler to automatically infer the schema from your CSVs.\n",
        "\n",
        "  * Go to **AWS Glue Console** -\\> **Crawlers** -\\> **Create crawler**.\n",
        "  * **Name:** `olist-crawler`.\n",
        "  * **Data source:** Add your S3 bucket path (e.g., `s3://olist-analytics-data-.../`).\n",
        "  * **IAM Role:** Create a new role (Glue will auto-generate one for you).\n",
        "  * **Output Database:** Click **Add database** and name it `olist_db`.\n",
        "  * **Schedule:** Set to **On demand**.\n",
        "  * **Run Crawler:** Once created, select the crawler and click **Run**. This will populate the `olist_db` with tables corresponding to your CSVs.\n",
        "\n",
        "-----\n",
        "\n",
        "## Phase 2: Analytics Environment (SageMaker AI)\n",
        "\n",
        "### 4\\. Open a SageMaker Serverless Notebook\n",
        "\n",
        "AWS has transitioned the notebook experience. We will use the **SageMaker AI** (formerly SageMaker Studio) interface.\n",
        "\n",
        "1.  Navigate to **Amazon SageMaker** in the AWS Console.\n",
        "2.  Click on **SageMaker AI** (or Studio) in the left sidebar.\n",
        "3.  Under the **Applications** section, select **JupyterLab**.\n",
        "4.  Create or Open a **Space**.\n",
        "5.  Inside the JupyterLab interface, you are running in a managed, serverless environment. Simply open a new `.ipynb` file using the **Python 3 (Data Science)** kernel.\n",
        "\n",
        "-----\n",
        "\n",
        "## Phase 3: Notebook Implementation\n",
        "\n",
        "### 5\\. Starter Code: Connection & Configuration\n",
        "\n",
        "You will need the `PyAthena` library. If it's not installed in your environment, run `!pip install pyathena` in the first cell."
      ],
      "metadata": {
        "id": "56f2d7-Nshhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyathena import connect\n",
        "\n",
        "# Configuration\n",
        "REGION = 'us-east-1' # Change to your region\n",
        "S3_STAGING_DIR = 's3://your-athena-query-results-bucket/' # Athena needs a place to store query metadata\n",
        "DATABASE = 'olist_db'\n",
        "\n",
        "# Establish Connection\n",
        "conn = connect(s3_staging_dir=S3_STAGING_DIR,\n",
        "               region_name=REGION)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "yu6NUQiSshht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6\\. Sample SQL Queries (Group By & Joins)\n",
        "\n",
        "These queries help you understand order volume and customer distribution."
      ],
      "metadata": {
        "id": "mKPEU6okshhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 1: Top 5 Cities by Order Count (Group By)\n",
        "query_1 = f\"\"\"\n",
        "SELECT\n",
        "    customer_city,\n",
        "    count(customer_id) as total_orders\n",
        "FROM \"{DATABASE}\".\"customers\"\n",
        "GROUP BY customer_city\n",
        "ORDER BY total_orders DESC\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "# Query 2: Joining Orders and Payments to find Revenue by Payment Type (Join)\n",
        "query_2 = f\"\"\"\n",
        "SELECT\n",
        "    p.payment_type,\n",
        "    SUM(p.payment_value) as total_revenue\n",
        "FROM \"{DATABASE}\".\"order_payments\" p\n",
        "JOIN \"{DATABASE}\".\"orders\" o ON p.order_id = o.order_id\n",
        "WHERE o.order_status = 'delivered'\n",
        "GROUP BY p.payment_type\n",
        "ORDER BY total_revenue DESC;\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "wd8ciyJ9shhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7\\. Import Results into Pandas DataFrame\n",
        "\n",
        "The most efficient way to handle this in SageMaker is to use the `pd.read_sql` function."
      ],
      "metadata": {
        "id": "69FM5Xt5shh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to execute and return DataFrame\n",
        "def get_athena_data(query):\n",
        "    return pd.read_sql(query, conn)\n",
        "\n",
        "# Load Top Cities into DF\n",
        "df_cities = get_athena_data(query_1)\n",
        "\n",
        "# Load Revenue Analysis into DF\n",
        "df_revenue = get_athena_data(query_2)\n",
        "\n",
        "# Display results\n",
        "print(\"Top Cities Analysis:\")\n",
        "print(df_cities.head())\n",
        "\n",
        "print(\"\\nRevenue by Payment Type:\")\n",
        "print(df_revenue.head())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "qCjBH3yoshh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use **SQL Magic commands**. This is often preferred by Data Engineers because it allows you to write raw SQL in a cell without wrapping it in Python strings, providing better syntax highlighting and readability.\n",
        "\n",
        "To do this, we use the `ipython-sql` extension and the `PyAthena` driver.\n",
        "\n",
        "### 1\\. Install and Load the Extension\n",
        "\n",
        "Run this in your first notebook cell to set up the environment:"
      ],
      "metadata": {
        "id": "0n2hrs2vs-YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary libraries\n",
        "!pip install ipython-sql pyathena --quiet\n",
        "\n",
        "# Load the SQL magic extension\n",
        "%load_ext sql"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "TUaXhusFs-YI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\. Connect to Athena\n",
        "\n",
        "Instead of a standard Python connection object, you will pass a connection string to the `%sql` magic command. Replace the placeholders with your specific S3 bucket (created in Step 1) and your region."
      ],
      "metadata": {
        "id": "mNofZ7Urs-YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse\n",
        "\n",
        "# Configuration\n",
        "region = \"us-east-1\"\n",
        "athena_db = \"olist_db\"\n",
        "# S3 path for Athena to store query results (must end with a /)\n",
        "s3_output = \"s3://olist-analytics-data-results/output/\"\n",
        "\n",
        "# Encode the S3 path for the connection string\n",
        "connection_string = f\"awsathena+rest://@athena.{region}.amazonaws.com/{athena_db}?s3_staging_dir={urllib.parse.quote_plus(s3_output)}\"\n",
        "\n",
        "# Connect the magic command to Athena\n",
        "%sql $connection_string"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "RdHysvKPs-YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 3\\. Run SQL Queries Directly in Cells\n",
        "\n",
        "Now you can use the `%%sql` prefix at the top of any cell to write pure SQL.\n",
        "\n",
        "**Example: Group By Analysis**\n",
        "\n",
        "```sql\n",
        "%%sql\n",
        "/* Find the top 5 product categories by number of items sold */\n",
        "SELECT\n",
        "    product_category_name,\n",
        "    COUNT(*) as items_sold\n",
        "FROM olist_order_items_dataset\n",
        "GROUP BY product_category_name\n",
        "ORDER BY items_sold DESC\n",
        "LIMIT 5;\n",
        "```\n",
        "\n",
        "**Example: Multi-Table Join**\n",
        "\n",
        "```sql\n",
        "%%sql\n",
        "/* Join orders and customers to see the delivery performance by state */\n",
        "SELECT\n",
        "    c.customer_state,\n",
        "    AVG(date_diff('day', CAST(o.order_purchase_timestamp AS TIMESTAMP), CAST(o.order_delivered_customer_date AS TIMESTAMP))) AS avg_delivery_days\n",
        "FROM olist_orders_dataset o\n",
        "JOIN olist_customers_dataset c ON o.customer_id = c.customer_id\n",
        "WHERE o.order_status = 'delivered'\n",
        "GROUP BY c.customer_state\n",
        "ORDER BY avg_delivery_days ASC\n",
        "LIMIT 10;\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "Since we are looking at the OLIST dataset—which is a treasure trove of Brazilian e-commerce history—we can dig into more complex \"business intelligence\" style queries.\n",
        "\n",
        "Here are three advanced SQL queries using **Window Functions**, **Date Arithmetic**, and **Complex Joins** to run directly in your SageMaker SQL cells.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Customer Retention: Repeat Purchase Behavior\n",
        "\n",
        "This query identifies \"Loyalists\" by calculating how many customers have placed more than one order. It requires joining the `orders` table with the `customers` table since `customer_id` in the orders table is unique per order, but `customer_unique_id` is the actual permanent ID for the person.\n",
        "\n",
        "```sql\n",
        "%%sql\n",
        "SELECT\n",
        "    CASE\n",
        "        WHEN order_count = 1 THEN 'One-time Buyer'\n",
        "        WHEN order_count = 2 THEN 'Repeat Buyer (2)'\n",
        "        ELSE 'Loyal Customer (3+)'\n",
        "    END AS customer_segment,\n",
        "    COUNT(*) as customer_count\n",
        "FROM (\n",
        "    SELECT\n",
        "        c.customer_unique_id,\n",
        "        COUNT(o.order_id) as order_count\n",
        "    FROM olist_orders_dataset o\n",
        "    JOIN olist_customers_dataset c ON o.customer_id = c.customer_id\n",
        "    GROUP BY c.customer_unique_id\n",
        ")\n",
        "GROUP BY 1\n",
        "ORDER BY customer_count DESC;\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Seasonality: Monthly Revenue Growth (%)\n",
        "\n",
        "This is a more advanced query using the **Window Function** `LAG()` to compare the current month's revenue to the previous month. This is a classic \"Solution Architect\" pattern for building executive dashboards.\n",
        "\n",
        "```sql\n",
        "%%sql\n",
        "WITH MonthlyRevenue AS (\n",
        "    SELECT\n",
        "        date_format(CAST(o.order_purchase_timestamp AS TIMESTAMP), '%Y-%m') AS order_month,\n",
        "        SUM(p.payment_value) AS revenue\n",
        "    FROM olist_orders_dataset o\n",
        "    JOIN olist_order_payments_dataset p ON o.order_id = p.order_id\n",
        "    WHERE o.order_status = 'delivered'\n",
        "    GROUP BY 1\n",
        ")\n",
        "SELECT\n",
        "    order_month,\n",
        "    revenue,\n",
        "    LAG(revenue) OVER (ORDER BY order_month) AS prev_month_revenue,\n",
        "    (revenue - LAG(revenue) OVER (ORDER BY order_month)) / LAG(revenue) OVER (ORDER BY order_month) * 100 AS pct_growth\n",
        "FROM MonthlyRevenue\n",
        "ORDER BY order_month;\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Logistic Bottlenecks: Estimated vs. Actual Delivery\n",
        "\n",
        "One of the biggest challenges in Brazilian e-commerce is geography. This query finds the states where the logistics gap (Difference between when the customer was *told* it would arrive vs. when it *actually* arrived) is the highest.\n",
        "\n",
        "```sql\n",
        "%%sql\n",
        "SELECT\n",
        "    c.customer_state,\n",
        "    COUNT(o.order_id) as total_orders,\n",
        "    AVG(date_diff('day', CAST(o.order_delivered_customer_date AS TIMESTAMP), CAST(o.order_estimated_delivery_date AS TIMESTAMP))) AS days_ahead_of_schedule,\n",
        "    SUM(CASE WHEN o.order_delivered_customer_date > o.order_estimated_delivery_date THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS percent_late\n",
        "FROM olist_orders_dataset o\n",
        "JOIN olist_customers_dataset c ON o.customer_id = c.customer_id\n",
        "WHERE o.order_status = 'delivered'\n",
        "  AND o.order_delivered_customer_date IS NOT NULL\n",
        "GROUP BY c.customer_state\n",
        "HAVING COUNT(o.order_id) > 100\n",
        "ORDER BY percent_late DESC;\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Tips for Athena Performance in SageMaker\n",
        "\n",
        "* **Case Sensitivity:** Athena tables and columns are usually lowercase. If your CSV headers had caps, the Glue Crawler might have lowercased them automatically.\n",
        "* **Date Casting:** OLIST timestamps are often stored as strings in CSVs. Notice I used `CAST(column AS TIMESTAMP)` in the queries above; this is essential for `date_diff` or `date_format` to work.\n",
        "\n",
        "**Next Step:** Would you like to see how to use **SageMaker Clarify** on these results to check for bias in your delivery times across different Brazilian states?\n",
        "-----\n",
        "\n",
        "\n",
        "### 4\\. Convert SQL Cell Results to Pandas\n",
        "\n",
        "One of the best features of SQL magic is that you can \"capture\" the output of a SQL cell directly into a Pandas DataFrame using the assignment syntax."
      ],
      "metadata": {
        "id": "nsTQqmzRs-YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the << operator to assign the result of the SQL query to a variable named 'df_performance'\n",
        "%%sql df_performance <<\n",
        "SELECT\n",
        "    order_status,\n",
        "    COUNT(*) as count\n",
        "FROM olist_orders_dataset\n",
        "GROUP BY order_status"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "LNIK9lQos-YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now 'df_performance' is a standard Pandas DataFrame\n",
        "print(type(df_performance))\n",
        "df_performance.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "toExDPYMs-YM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "**Next Step:** Would you like to see how to create a **SageMaker Feature Store** from these SQL results to prepare the data for an ML model?"
      ],
      "metadata": {
        "id": "XbGgr8zZs-YM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an AWS Solutions Architect, I recommend using **Seaborn** for visualizations in SageMaker because it handles Pandas DataFrames natively and produces \"production-ready\" aesthetics with very little code.\n",
        "\n",
        "Below is the code to pull the data from Athena into Pandas and generate three key business insights: **Revenue Trends**, **Payment Preferences**, and **Category Performance**.\n",
        "\n",
        "### 1\\. Setup and Library Imports\n",
        "\n",
        "Run this in a new cell to prepare your plotting environment."
      ],
      "metadata": {
        "id": "wXllgwYhuFY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Set the visual style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "7t1XHFDcuFY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 2\\. Visualization 1: Monthly Revenue Trend (Growth Analysis)\n",
        "\n",
        "We will pull the monthly revenue to see how the business is scaling."
      ],
      "metadata": {
        "id": "zHPptInluFZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query data into a DataFrame\n",
        "df_revenue_trend = get_athena_data(f\"\"\"\n",
        "    SELECT\n",
        "        date_format(CAST(o.order_purchase_timestamp AS TIMESTAMP), '%Y-%m-01') AS month,\n",
        "        SUM(p.payment_value) AS total_revenue\n",
        "    FROM \"{DATABASE}\".\"olist_orders_dataset\" o\n",
        "    JOIN \"{DATABASE}\".\"olist_order_payments_dataset\" p ON o.order_id = p.order_id\n",
        "    WHERE o.order_status = 'delivered'\n",
        "    GROUP BY 1\n",
        "    ORDER BY 1\n",
        "\"\"\")\n",
        "\n",
        "# Convert month string to datetime for better plotting\n",
        "df_revenue_trend['month'] = pd.to_datetime(df_revenue_trend['month'])\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df_revenue_trend, x='month', y='total_revenue', marker='o', color='#2ecc71')\n",
        "plt.title('OLIST Monthly Revenue Trend (BRL)', fontsize=15)\n",
        "plt.xlabel('Order Month')\n",
        "plt.ylabel('Revenue')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "l108sPonuFZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 3\\. Visualization 2: Payment Method Distribution\n",
        "\n",
        "This helps identify the most popular financial rails in the Brazilian market."
      ],
      "metadata": {
        "id": "RCJ18ck-uFZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query data\n",
        "df_payments = get_athena_data(f\"\"\"\n",
        "    SELECT payment_type, COUNT(*) as count\n",
        "    FROM \"{DATABASE}\".\"olist_order_payments_dataset\"\n",
        "    GROUP BY payment_type\n",
        "    ORDER BY count DESC\n",
        "\"\"\")\n",
        "\n",
        "# Plotting a Pie Chart (better for distribution)\n",
        "plt.figure(figsize=(8, 8))\n",
        "colors = sns.color_palette('pastel')[0:5]\n",
        "plt.pie(df_payments['count'], labels=df_payments['payment_type'], autopct='%1.1f%%', colors=colors, startangle=140)\n",
        "plt.title('Customer Payment Method Distribution', fontsize=15)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "mhehCNkBuFZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 4\\. Visualization 3: Top 10 Product Categories by Revenue\n",
        "\n",
        "This join-heavy query identifies which categories drive the most value."
      ],
      "metadata": {
        "id": "NrW_pVVMuFZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query data\n",
        "df_top_categories = get_athena_data(f\"\"\"\n",
        "    SELECT\n",
        "        p.product_category_name,\n",
        "        SUM(i.price) as total_sales\n",
        "    FROM \"{DATABASE}\".\"olist_order_items_dataset\" i\n",
        "    JOIN \"{DATABASE}\".\"olist_products_dataset\" p ON i.product_id = p.product_id\n",
        "    WHERE p.product_category_name IS NOT NULL\n",
        "    GROUP BY p.product_category_name\n",
        "    ORDER BY total_sales DESC\n",
        "    LIMIT 10\n",
        "\"\"\")\n",
        "\n",
        "# Plotting a Horizontal Bar Chart\n",
        "sns.barplot(data=df_top_categories, x='total_sales', y='product_category_name', palette='viridis')\n",
        "plt.title('Top 10 Product Categories by Revenue', fontsize=15)\n",
        "plt.xlabel('Total Sales (BRL)')\n",
        "plt.ylabel('Category Name')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YAY9UuX1uFZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 5\\. Architectural Tip: Handling \"Big Data\" in SageMaker\n",
        "\n",
        "If your OLIST dataset grows to millions of rows:\n",
        "\n",
        "1.  **Sampling:** Use `TABLESAMPLE BERNOULLI (10)` in your SQL query to pull only a 10% representative sample into Pandas to save memory.\n",
        "2.  **Parquet Conversion:** In Step 3 (Crawler), if you convert your CSVs to **Parquet** format in S3, your Athena queries will run up to **10x faster** and cost **90% less** because Athena only reads the columns needed for the visualization.\n",
        "\n",
        "**Next Step:** Would you like to build a **Linear Regression model** in this notebook to predict future delivery times based on the geographic data we just visualized?"
      ],
      "metadata": {
        "id": "aDntu1_VuFZG"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}